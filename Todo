2008-08-29  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* apropos missing: we have no push, we never know the downstream
	servers. People who know their downstream hosts and want to ascertain
	something will want additional methods we have never thought about, like
	update or delete a certain file.

2008-08-26  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* tempted to refactor rmirror into resolve_symlink, localize, etc.
	Curious if rsync_options=links equal 0 vs. 1 will make the expected
	difference.

	* rsync options: it's a bit of a pain that we usually need several rsync
	options, like compress, links, times, checksum and that there is no
	reasonable default except the original rsync default. I think wee can
	safely assume that the rsync options are shared between all recentfile
	instances within one recent tree.

2008-08-20  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* deletes: if a delete follows an add quickly enough it may happen that
	a downstream mirror did not see the add at all! It seems this needs to
	be mentioned somewhere. The point here is that even if the downstream is
	never missing the principal timeframe it may encounter a "delete" that
	has no complimentary "add" anywhere.

2008-08-19  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* I suspect the treat of metadata is incorrect during read or something.
	The bug that I am watching is that between 06:08 and 06:09 the 6h file
	contained more than 6 hours worth of data. At 06:08 we merged into the
	1d file. We need to take snapshots of the 6h file over the course of an
	hour or maybe only between XX:08 and XX:09? Nope, the latter is not
	enough.

	Much worse: watching the 1h file: right at the moment (at 06:35) it
	covers 1218867584-1219120397 which is 70 hours.

	Something terribly broken. BTW, 1218867584 corresponds to Sat Aug 16
	08:19:44 2008, that is when I checked out last time, so it seems to be
	aggregating and never truncating?

	No, correct is: it is never truncating; but wrong is: it is aggregating.
	It does receive a lot of events from time to time from a larger file.
	Somehow a large file gets merged into the small one and because the
	"meta/merged" attribute is missing, nobody is paying attention. I
	believe that I can fix this by making sure that metadata are honoured
	during read. DONE and test adjusted.

2008-08-17  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* grand renaming plan

	remotebase          => remoteroot   to fit well with localroot        DONE
	local_path()        => localroot    seems to me should already work   DONE
	recentfile_basename => rfilename    no need to stress it has no slash DONE

	filenameroot??? Doesn't seem too bad to me today. Maybe something like
	kern? It would anyway need a deprecation cycle because it is an
	important constructor.

	* I like the portability that Data::Serializer brings us but the price
	is that some day we might find out that it is slowing us a bit. We'll
	see.

2008-08-16  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* should we not enter the interval of the principal (or the interval of
	the merging file?) in every aggregated/merged file?

	* we should aim at a first release and give up on thinking about
	sanitizing stuff and zloop. Let's just admit that a full traditional
	rsync is the only available sanitizer ATM. Otherwise it's complicated
	stuff: sanitizing on the origin server, sanitizing on the slaves,
	sanitizing forgotten files, broken timestamps, etc. Let's delay it and
	get the basics out before this becomes a major cause for mess.

2008-08-13  Andreas Koenig  <k@andreas-koenigs-computer.local>

	* On OSes not supporting symlinks we expect that RECENT.recent contains
	the contents of the principal recentfile. Actually this is identical on
	systems supporting symlinks. Simple, what follows from that is that we
	need to keep the serializer in the metadata because we cannot read it
	from the filename, doesn't it? Of course not. It's a chicken and egg
	problem. This leaves us with the problem to actually parse the
	serialized data to find out in which format it is. So who can do the 4
	or 5 magics we wanted to support? File::LibMagic?

2008-08-09  Andreas Koenig  <k@andreas-koenigs-computer.local>

	* remotebase and recentfile_basename are ugly names. Now that we need a
	word for the shortest/principal/driving recentfile too we should do
	something about it.

	localroot is good. rfile is good. local_path() is bad, local_path($path)
	is medium, filenameroot() is bad, remotebase is bad, recentfile is
	already deprecated.

	Up to now remotebase was the string that described the remote root
	directory in rsync notation, like pause.perl.org::authors. And
	recentfile_basename was "RECENT-1h.yaml".

2008-08-08  Andreas Koenig  <k@andreas-koenigs-computer.local>

	* The test that was added in today's checkin is a good start for a test
	of rmirror. We should have more methods in Recent.pm: verify,
	addmissingfiles. We should verify the current tree, then rmirror it and
	then verifytree the copy. We could then add some arbitrary file and let
	it be discovered by addmissingfiles, then rmirror again and then
	verifytree the copy again.

	Then we could start stealing from csync2 sqlite database [no port to
	OSX!] and fill a local DB. And methods to compare the database with the
	recentfiles. Our strength is that in principle we could maintain state
	with a single float. We have synced up to 1234567890.123456. If the Z
	file does not add new files all we have to do is mirror the new ones and
	delete the goners.

	This makes it clear that we should extend current protocol and declare
	that we cheat when we add files too late, just to help the other end
	keeping track. Ah yes, that's what was meant when zloop was mentioned
	earlier.

	Maybe need to revisit File::Mirror to help me with this task.

2008-08-07  Andreas Koenig  <k@andreas-koenigs-computer.local>

	* There must be an allow-me-to-truncate flag in every recentfile.
	Without it one could construct a sequence of updates winning the locking
	battle against the aggregator. Only if an aggregator has managed to
	merge data over to the next level, truncating can be allowed. DONE with
	accessor merged.

2008-08-06  Andreas Koenig  <k@andreas-koenigs-computer.local>

	* We should probably guarantee that no duplicates enter the aggregator
	array.

2008-08-02  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* To get merge operation faster would need a good benchmark test. What
	02 spits out isn't reliable enough and is dominated by many other
	things. Between

	commit 10176bf6b79865d4fe9f46e3857a3b8669fa7961
	Author: Andreas J. Koenig <k@k75.(none)>
	Date:   Sat Aug 2 07:58:04 2008 +0200

	and

	commit 3243120a0c120aaddcd9b1f4db6689ff12ed2523
	Author: Andreas J. Koenig <k@k75.(none)>
	Date:   Sat Aug 2 11:40:29 2008 +0200

	there was a lot of trying but the effect is hardly measurable with
	current tests.	

	* overhead of connecting seems high. When setting
	max_files_per_connection to 1 we see that.

2008-08-01  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* 1217622571.0889 - 1217597432.86734 = 25138.2215600014

	25138.2215600014/3600 = 6.98283932222261

	It jumps into the eye that this is ~ 7 hours, not ~6, so there seems to
	be a bug in the aggregator. FIXED

2008-07-27  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* e.g. id/Y/YE/YEWENBIN/Emacs-PDE-0.2.16.tar.gz: Do we have it, should
	we have it, can we mirror it, mirror it!

	I fear this needs a new class which might be called
	File::Rsync::Mirror::Recent. It would collect all recentfiles of a kind
	and treat them as an entity. I realize that a single recentfile may be
	sufficient for certain tasks and that it is handy for the low level
	programmer but it is not nice to use. If there is a delete in the 1h
	file then the 6h file still contains it. Seekers of the best information
	need to combine at least some of the recentfiles most of the time.

	There is the place for the Z loop!

	But the combination is something to collect in a database, isn't it. Did
	csync2 just harrumph?

2008-07-26  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* it just occurred to me that hosts in the same mirroring pool could
	help out each other even without rewriting the recentfile. Just fetch
	the stuff to mirror from several places, bingo. But that's something
	that should rather live in a separate package or in rsync directly.

	* cronjobs are unsuited because with ntp they would all come at the full
	minute and disturb each other. Besides that I'd hate to have a backbone
	with more than a few seconds latency.

2008-07-25  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* a second rsync server with access control for PAUSE. Port? 873 is the
	standard port, let's take 8873.

	* if there were a filesystem based on this, it would have a slow access
	to inexistent files. It would probably provide wrong readdir (only based
	on current content) or also a slow one (based on a recentfile written
	after the call). But it would provide fast access to existing files. Or
	one would deliberately allow slightly blurred answers based on some
	sqlite reflection of the recentfiles.

	* todo: write a variant of mirror() that combines two or more
	recentfiles and treats them like one

	* todo: signal handler to remove the tempfile

2008-07-24  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* now that we have the symlink I forgot how it should be used in
	practice.

	* the z loop: add missing files to Z file. Just append them (instead of
	prepending). So one guy prepends something from the Y file from time to
	time and another guy appends something rather frequently. Collecting
	pond. When Y merges into Z, things get epoch and the collecting pond
	gets smaller. What exactly are "missing files"?

	take note of current epoch of the alpha file, let's call it the
	recent-ts

	find all files on disk

	remove all files registered in the recentworld up to recent-ts

	remove all files that have been deleted after recent-ts according to
	recentworld

2008-07-23  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* rersyncrecent might be a cronjob with a (locked) state file which
	contains things like after and maybe last z sync or such?

	rrr-mirror might be an alternative name but how would we justify the
	three Rs when there is no Re-Rsync-Recent?

	With the --loop parameter it is an endless loop, without it is no loop.
	At least this is simple.

	* todo: new accssor z-interval specifies how often the Z file is updated
	against the filesystem. We probably want no epoch stamp on these
	entries. And we want to be able to filter the entries (e.g. no
	by-modules and by-category tree)

2008-07-20  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* Fill the Z file. gc or fsck or both. Somehow we must get the old files
	into Z. We do not need the other files filled up with filesystem
	contents though.

	* need interface to query for a file in order to NOT call update on
	PAUSE a second time within a short time.

2008-07-19  Andreas J. Koenig  <andreas.koenig.7os6VVqR@franz.ak.mind.de>

	* recommended update interval? Makes no sense, is different for
	different users.

	* Moosify

	Local Variables:
	mode: change-log
	change-log-default-name: "Todo"
	tab-width: 2
	left-margin: 2
	End:
